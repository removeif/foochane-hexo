---
title: 文本分类之文本预处理
summary: 关键词：文本预处理 读取数据 去除文本中非汉字的内容 文本分词 去除停止词 保存文件 xlsx表格保存成cvs格式
author: foochane
top: false
cover: false
categories: NLP
date: 2019-09-01 11:23
urlname: 2019090101
tags:
  - 文本分类
---



## 1 读取数据


```python
import pandas as pd
data=pd.read_excel('data/复旦大学中文文本分类语料.xlsx','sheet1',encoding='utf-8') 
```

查看数据信息

```python

data.head()

```


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>分类</th>
      <th>正文</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2432\n【原文出处】出版发行研究\n【原刊地名】京\n【原刊期号】1...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2435\n【原文出处】扬州师院学报：社科版\n【原刊期号】199504...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2785\n【原文出处】南通师专学报：社科版\n【原刊期号】199503...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3021\n【原文出处】社会科学战线\n【原刊地名】长春\n【原刊期号】...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3062\n【原文出处】上海文化\n【原刊期号】199505\n【原刊页...</td>
    </tr>
  </tbody>
</table>
</div>


查看分类种类
```python

data['分类'].unique()

```

```
array(['艺术', '文学', '哲学', '通信', '能源', '历史', '矿藏', '空间', '教育', '交通', '计算机',
       '环境', '电子', '农业', '体育', '时政', '医疗', '经济', '法律'], dtype=object)
```
## 2 去除文本中非汉字的内容

定义函数

```python
import re

# 提取汉字
def find_chinese(file):
    pattern = re.compile(r'[^\u4e00-\u9fa5]')
    chinese = re.sub(pattern, '', file)
    return chinese

# 提取非汉字字符
def find_unchinese(file):
    pattern = re.compile(r'[\u4e00-\u9fa5]')
    unchinese = re.sub(pattern,"",file)
    return unchinese

```

```python

data['处理后的正文'] = data['正文'].apply(lambda x: find_chinese(x))

```


```python

data.head()

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>分类</th>
      <th>正文</th>
      <th>处理后的正文</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2432\n【原文出处】出版发行研究\n【原刊地名】京\n【原刊期号】1...</td>
      <td>文献号原文出处出版发行研究原刊地名京原刊期号原刊页号分类号分类名出版工作图书评介作者王益复印...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2435\n【原文出处】扬州师院学报：社科版\n【原刊期号】199504...</td>
      <td>文献号原文出处扬州师院学报社科版原刊期号原刊页号分类号分类名出版工作图书评介作者王菊延复印期...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2785\n【原文出处】南通师专学报：社科版\n【原刊期号】199503...</td>
      <td>文献号原文出处南通师专学报社科版原刊期号原刊页号分类号分类名语言文字学作者咏枫复印期号标题语...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3021\n【原文出处】社会科学战线\n【原刊地名】长春\n【原刊期号】...</td>
      <td>文献号原文出处社会科学战线原刊地名长春原刊期号原刊页号分类号分类名文艺理论作者李心峰复印期号...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3062\n【原文出处】上海文化\n【原刊期号】199505\n【原刊页...</td>
      <td>文献号原文出处上海文化原刊期号原刊页号分类号分类名文艺理论作者朱立元复印期号标题中西古代艺术...</td>
    </tr>
  </tbody>
</table>
</div>



## 3 文本分词

使用结巴分词

```python
import jieba
jieba.enable_parallel(6) #并行分词开启
data['处理后的正文']  = data['处理后的正文'].apply(lambda i:jieba.cut(i))
data['处理后的正文']  = [' '.join(i) for i in data['处理后的正文']]
```

    Building prefix dict from the default dictionary ...
    Loading model from cache /tmp/jieba.cache
    Loading model cost 0.699 seconds.
    Prefix dict has been built succesfully.



```python

data.head()

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>分类</th>
      <th>正文</th>
      <th>处理后的正文</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2432\n【原文出处】出版发行研究\n【原刊地名】京\n【原刊期号】1...</td>
      <td>文献号 原文 出处 出版发行 研究 原刊 地名 京原 刊期 号 原刊 页 号 分类号 分类 ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2435\n【原文出处】扬州师院学报：社科版\n【原刊期号】199504...</td>
      <td>文献号 原文 出处 扬州 师院 学报 社科 版原 刊期 号 原刊 页 号 分类号 分类 名 ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-2785\n【原文出处】南通师专学报：社科版\n【原刊期号】199503...</td>
      <td>文献号 原文 出处 南通 师专 学报 社科 版原 刊期 号 原刊 页 号 分类号 分类 名 ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3021\n【原文出处】社会科学战线\n【原刊地名】长春\n【原刊期号】...</td>
      <td>文献号 原文 出处 社会科学 战线 原刊 地名 长春 原刊 期号 原刊 页 号 分类号 分类...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>艺术</td>
      <td>﻿【 文献号 】1-3062\n【原文出处】上海文化\n【原刊期号】199505\n【原刊页...</td>
      <td>文献号 原文 出处 上海 文化 原刊 期号 原刊 页 号 分类号 分类 名 文艺理论 作者 ...</td>
    </tr>
  </tbody>
</table>
</div>



## 4 去除停止词


```python
stop = [line.strip() for line in open('data/停用词汇总.txt','r',encoding='utf-8').readlines()]
data['处理后的正文'] = data['处理后的正文'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))
```

## 5 保存文件


```python
import os 
if not os.path.exists('./output'):
    os.mkdir('./output')

f_data = open('./output/data_clean_split.txt','w',encoding='utf-8')
for i in range (len(data)):
    line = data['分类'][i] + '\t' + data['处理后的正文'][i] + '\n'
    f_data.write(line)
print("写入成功.....")

f_data.close()
```

## 6 xlsx表格保存成cvs格式

读取数据

```python

import pandas as pd
data=pd.read_excel('data/复旦大学中文文本分类语料.xlsx','sheet1',encoding='utf-8')

```
保存
```python
import os 
if not os.path.exists('./output'):
    os.mkdir('./output')
data.to_csv('./output/fudan_corpus.csv',encoding='utf-8')
```